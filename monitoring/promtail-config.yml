# JobBot Promtail Configuration
# Log collection and forwarding to Loki

server:
  http_listen_port: 9080
  grpc_listen_port: 0

positions:
  filename: /tmp/positions.yaml

clients:
  - url: http://loki:3100/loki/api/v1/push

scrape_configs:
  # JobBot Backend Application Logs
  - job_name: jobbot-backend
    static_configs:
      - targets:
          - localhost
        labels:
          job: jobbot-backend
          service: api
          environment: production
          __path__: /var/log/backend/*.log

    pipeline_stages:
      # Parse timestamp and level from structured logs
      - regex:
          expression: '(?P<timestamp>\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2},\d{3}) - (?P<level>\w+) - (?P<logger>[\w.]+) - (?P<message>.*)'
      
      # Convert log level to standard format
      - template:
          source: level
          template: '{{ ToLower .Value }}'
      
      # Parse JSON messages if present
      - json:
          expressions:
            user_id: user_id
            request_id: request_id
            endpoint: endpoint
            method: method
            status_code: status_code
            duration: duration
      
      # Add labels
      - labels:
          level:
          logger:
          user_id:
          endpoint:
          method:
      
      # Parse and format timestamp
      - timestamp:
          source: timestamp
          format: '2006-01-02 15:04:05,000'
      
      # Add metrics
      - metrics:
          api_requests_total:
            type: Counter
            description: "Total number of API requests"
            source: message
            config:
              action: inc
              match_all: true
          
          api_request_duration_seconds:
            type: Histogram
            description: "API request duration"
            source: duration
            config:
              buckets: [0.1, 0.5, 1.0, 2.0, 5.0]

  # Nginx Access Logs
  - job_name: nginx-access
    static_configs:
      - targets:
          - localhost
        labels:
          job: nginx-access
          service: nginx
          environment: production
          __path__: /var/log/nginx/access.log

    pipeline_stages:
      # Parse nginx access log format
      - regex:
          expression: '(?P<remote_addr>[\d.]+) - (?P<remote_user>\S+) \[(?P<time_local>[^\]]+)\] "(?P<method>\S+) (?P<path>\S+) (?P<protocol>\S+)" (?P<status>\d+) (?P<body_bytes_sent>\d+) "(?P<http_referer>[^"]*)" "(?P<http_user_agent>[^"]*)" "(?P<http_x_forwarded_for>[^"]*)" rt=(?P<request_time>[\d.]+) uct="(?P<upstream_connect_time>[^"]*)" uht="(?P<upstream_header_time>[^"]*)" urt="(?P<upstream_response_time>[^"]*)"'
      
      # Add labels
      - labels:
          method:
          status:
          remote_addr:
      
      # Parse timestamp
      - timestamp:
          source: time_local
          format: '02/Jan/2006:15:04:05 -0700'
      
      # Add metrics
      - metrics:
          nginx_requests_total:
            type: Counter
            description: "Total number of nginx requests"
            config:
              action: inc
          
          nginx_request_duration_seconds:
            type: Histogram
            description: "Nginx request duration"
            source: request_time
            config:
              buckets: [0.1, 0.5, 1.0, 2.0, 5.0]

  # Nginx Error Logs
  - job_name: nginx-error
    static_configs:
      - targets:
          - localhost
        labels:
          job: nginx-error
          service: nginx
          environment: production
          log_type: error
          __path__: /var/log/nginx/error.log

    pipeline_stages:
      # Parse nginx error log format
      - regex:
          expression: '(?P<timestamp>\d{4}/\d{2}/\d{2} \d{2}:\d{2}:\d{2}) \[(?P<level>\w+)\] (?P<pid>\d+)#(?P<tid>\d+): (?P<message>.*)'
      
      # Add labels
      - labels:
          level:
          pid:
      
      # Parse timestamp
      - timestamp:
          source: timestamp
          format: '2006/01/02 15:04:05'

  # PostgreSQL Logs
  - job_name: postgres
    static_configs:
      - targets:
          - localhost
        labels:
          job: postgres
          service: database
          environment: production
          __path__: /var/log/postgresql/*.log

    pipeline_stages:
      # Parse PostgreSQL log format
      - regex:
          expression: '(?P<timestamp>\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}.\d{3} \w{3}) \[(?P<pid>\d+)\]: \[(?P<line_num>\d+)-1\] user=(?P<user>\w*),db=(?P<database>\w*),app=(?P<application>\w*),client=(?P<client>[\d.]*) (?P<level>\w+): (?P<message>.*)'
      
      # Add labels
      - labels:
          level:
          user:
          database:
          application:
          client:
      
      # Parse timestamp
      - timestamp:
          source: timestamp
          format: '2006-01-02 15:04:05.000 MST'

  # Redis Logs
  - job_name: redis
    static_configs:
      - targets:
          - localhost
        labels:
          job: redis
          service: cache
          environment: production
          __path__: /var/log/redis/*.log

    pipeline_stages:
      # Parse Redis log format
      - regex:
          expression: '(?P<pid>\d+):(?P<role>\w) (?P<timestamp>\d{2} \w{3} \d{4} \d{2}:\d{2}:\d{2}.\d{3}) (?P<level>[*#.-]) (?P<message>.*)'
      
      # Convert Redis log level symbols to standard levels
      - template:
          source: level
          template: '{{ if eq .Value "*" }}info{{ else if eq .Value "#" }}warning{{ else if eq .Value "." }}debug{{ else }}error{{ end }}'
      
      # Add labels
      - labels:
          level:
          role:
          pid:
      
      # Parse timestamp
      - timestamp:
          source: timestamp
          format: '02 Jan 2006 15:04:05.000'

  # Docker Container Logs
  - job_name: docker
    static_configs:
      - targets:
          - localhost
        labels:
          job: docker
          environment: production
          __path__: /var/lib/docker/containers/*/*-json.log

    pipeline_stages:
      # Parse Docker JSON log format
      - json:
          expressions:
            log: log
            stream: stream
            time: time
            attrs: attrs
      
      # Extract container labels from file path
      - regex:
          source: filename
          expression: '/var/lib/docker/containers/(?P<container_id>[^/]+)/[^/]+-json\.log'
      
      # Add labels
      - labels:
          container_id:
          stream:
      
      # Use log field as the actual log message
      - output:
          source: log
      
      # Parse timestamp
      - timestamp:
          source: time
          format: RFC3339Nano

  # Celery Worker Logs
  - job_name: celery-worker
    static_configs:
      - targets:
          - localhost
        labels:
          job: celery-worker
          service: background-tasks
          environment: production
          __path__: /var/log/backend/celery-worker.log

    pipeline_stages:
      # Parse Celery log format
      - regex:
          expression: '\[(?P<timestamp>\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2},\d{3}): (?P<level>\w+)/(?P<process>\w+)\] (?P<task>[\w.]*) (?P<message>.*)'
      
      # Add labels
      - labels:
          level:
          process:
          task:
      
      # Parse timestamp
      - timestamp:
          source: timestamp
          format: '2006-01-02 15:04:05,000'

  # System Logs (if accessible)
  - job_name: syslog
    static_configs:
      - targets:
          - localhost
        labels:
          job: syslog
          service: system
          environment: production
          __path__: /var/log/syslog

    pipeline_stages:
      # Parse syslog format
      - regex:
          expression: '(?P<timestamp>\w{3} \d{1,2} \d{2}:\d{2}:\d{2}) (?P<hostname>\S+) (?P<service>\w+)(\[(?P<pid>\d+)\])?: (?P<message>.*)'
      
      # Add labels
      - labels:
          hostname:
          service:
          pid:
      
      # Parse timestamp (current year assumed)
      - timestamp:
          source: timestamp
          format: 'Jan 2 15:04:05'