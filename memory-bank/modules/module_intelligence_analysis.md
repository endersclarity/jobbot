# Module: Intelligence Analysis

## Purpose & Responsibility
The Intelligence Analysis module transforms raw scraped data into actionable business intelligence by extracting, normalizing, and analyzing job market data, company information, and technology trends. This module serves as the critical processing layer that converts unstructured web content into structured, queryable data suitable for opportunity detection and business strategy formulation.

## Interfaces
* `DataProcessor`: Core data processing pipeline
  * `extract_job_data()`: Parse HTML and extract structured job information
  * `normalize_fields()`: Standardize salary, location, and job type data
  * `detect_duplicates()`: Identify and merge duplicate job postings
  * `validate_quality()`: Ensure data meets quality standards
* `CompanyAnalyzer`: Business intelligence extraction
  * `analyze_tech_stack()`: Detect technology usage from job requirements
  * `identify_pain_points()`: Extract automation opportunities from descriptions
  * `score_companies()`: Rank companies by automation potential
* `TrendAnalyzer`: Market intelligence
  * `detect_skill_trends()`: Identify emerging technology demands
  * `analyze_salary_ranges()`: Track compensation trends by role and location
  * `monitor_hiring_patterns()`: Detect company growth and contraction signals
* Input: Raw HTML/JSON files from scraped_data/raw/
* Output: Structured data in scraped_data/processed/, normalized database records

## Implementation Details
* Files:
  - `app/processing/html_parser.py` - HTML parsing and data extraction logic
  - `app/processing/normalizer.py` - Data standardization and field normalization
  - `app/processing/deduplication.py` - Duplicate detection and merging algorithms
  - `app/processing/quality_monitor.py` - Data quality validation and reporting
  - `app/analysis/tech_stack_detector.py` - Technology trend analysis
  - `app/analysis/opportunity_scorer.py` - Business opportunity scoring algorithms
* Important algorithms:
  - Fuzzy string matching for duplicate detection (Levenshtein distance)
  - Natural language processing for skill extraction
  - Statistical analysis for trend detection
  - Machine learning models for company scoring
* Data Models
  - `ProcessedJobData`: Cleaned and normalized job information
  - `CompanyProfile`: Aggregated company intelligence and metrics
  - `TechnologyTrend`: Market trends and skill demand analytics
  - `QualityMetrics`: Data processing performance and accuracy tracking

## Current Implementation Status (Updated 2025-05-30)
* âœ… Completed:
  - Database schema with all Phase 3B fields (salary_min/max, location, job_type, experience_level, status)
  - HTML parsing infrastructure with comprehensive JobDataExtractor
  - Field extraction for job titles, companies, locations, salary ranges
  - Field normalization (salary parsing, location standardization, job type categorization)
  - Data validation and quality checking logic
  - JSON processing for multiple scraper output formats
* ðŸš§ In Progress:
  - Data Normalization Pipeline (Task #3) - Ready to start implementation
  - Advanced salary parsing with regex patterns and K notation handling
* ðŸ“‹ Pending:
  - Fuzzy matching algorithm for content-based deduplication (Task #4)
  - Technology stack detection from job requirements
  - Company profiling and intelligence aggregation
  - Machine learning model training for opportunity scoring
  - Real-time trend analysis and alerting
  - Competitive intelligence gathering

## Implementation Plans & Tasks
* `implementation_phase_3b.md`
  - [Data Normalization]: Standardize all extracted fields to consistent formats
  - [Deduplication Engine]: Implement sophisticated duplicate detection and merging
  - [Quality Assurance]: Build comprehensive data validation and monitoring
  - [Batch Processing]: Create efficient pipeline for processing large datasets
* `implementation_strategic_pivot.md`
  - [Company Intelligence]: Develop comprehensive business profiling capabilities
  - [Opportunity Detection]: Build ML models for automation potential scoring
  - [Market Analysis]: Implement trend detection and competitive intelligence
  - [Technology Tracking]: Monitor emerging skills and technology adoption

## Mini Dependency Tracker
---mini_tracker_start---
Dependencies:
- Data Collection module (raw scraped data)
- Machine learning libraries (scikit-learn, pandas, numpy)
- Natural language processing tools (spaCy, NLTK)
- Database infrastructure for processed data storage

Dependents:
- Opportunity Detection module (requires processed company intelligence)
- Dashboard Interface module (consumes analytics and trends)
- Solution Generation module (uses company profiles for targeting)
---mini_tracker_end---